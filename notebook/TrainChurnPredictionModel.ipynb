{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import azureml.core\n",
        "\n",
        "from azureml.core import Experiment, Workspace, Dataset, Datastore\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from notebookutils import mssparkutils\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "microsoft": {}
      },
      "outputs": [],
      "source": [
        "df = spark.read.load('abfss://files@datalakexxxxxxx.dfs.core.windows.net/data/ml/customer_churn.csv', format='csv',\n",
        "    header=True,\n",
        "    inferSchema=True\n",
        ")\n",
        "display(df.limit(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "columns = [\"ChurnLabel\", \"ChurnScore\", \"ChurnCategory\", \"ChurnReason\"]\n",
        "\n",
        "df = df.drop(*columns)\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "linkedService_name = \"AzureMLService1\"\n",
        "experiment_name = \"customer-churn-prediction\"\n",
        "\n",
        "ws = mssparkutils.azureML.getWorkspace(linkedService_name)\n",
        "experiment = Experiment(ws, experiment_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "datastore = Datastore.get_default(ws)\n",
        "dataset = TabularDatasetFactory.register_spark_dataframe(df, datastore, name=experiment_name + \"-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "automl_config = AutoMLConfig(spark_context = sc,\n",
        "                             task = \"classification\",\n",
        "                             training_data = dataset,\n",
        "                             label_column_name = \"ChurnValue\",\n",
        "                             primary_metric = \"accuracy\",\n",
        "                             experiment_timeout_hours = 0.25,\n",
        "                             max_concurrent_iterations = 2,\n",
        "                             enable_onnx_compatible_models = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "run = experiment.submit(automl_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "displayHTML(\"<a href={} target='_blank'>Your experiment in Azure Machine Learning portal: {}</a>\".format(run.get_portal_url(), run.id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import onnxruntime\n",
        "import mlflow\n",
        "import mlflow.onnx\n",
        "\n",
        "from mlflow.models.signature import ModelSignature\n",
        "from mlflow.types import DataType\n",
        "from mlflow.types.schema import ColSpec, Schema\n",
        "\n",
        "# Get best model from automl run\n",
        "best_run, onnx_model = run.get_output(return_onnx_model=True)\n",
        "\n",
        "# Define utility functions to infer the schema of ONNX model\n",
        "def _infer_schema(data):\n",
        "    res = []\n",
        "    for _, col in enumerate(data):\n",
        "        t = col.type.replace(\"tensor(\", \"\").replace(\")\", \"\")\n",
        "        if t in [\"bool\"]:\n",
        "            dt = DataType.boolean\n",
        "        elif t in [\"int8\", \"uint8\", \"int16\", \"uint16\", \"int32\"]:\n",
        "            dt = DateType.integer\n",
        "        elif t in [\"uint32\", \"int64\"]:\n",
        "            dt = DataType.long\n",
        "        elif t in [\"float16\", \"bfloat16\", \"float\"]:\n",
        "            dt = DataType.float\n",
        "        elif t in [\"double\"]:\n",
        "            dt = DataType.double\n",
        "        elif t in [\"string\"]:\n",
        "            dt = DataType.string\n",
        "        else:\n",
        "            raise Exception(\"Unsupported type: \" + t)\n",
        "        res.append(ColSpec(type=dt, name=col.name))\n",
        "    return Schema(res)\n",
        "\n",
        "def _infer_signature(onnx_model):\n",
        "    onnx_model_bytes = onnx_model.SerializeToString()\n",
        "    onnx_runtime = onnxruntime.InferenceSession(onnx_model_bytes)\n",
        "    inputs = _infer_schema(onnx_runtime.get_inputs())\n",
        "    outputs = _infer_schema(onnx_runtime.get_outputs())\n",
        "    return ModelSignature(inputs, outputs)\n",
        "\n",
        "# Infer signature of ONNX model\n",
        "signature = _infer_signature(onnx_model)\n",
        "\n",
        "artifact_path = experiment_name + \"_artifact\"\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
        "mlflow.set_experiment(experiment_name)\n",
        "\n",
        "with mlflow.start_run() as run:\n",
        "    # Save the model to the outputs directory for capture\n",
        "    mlflow.onnx.log_model(onnx_model, artifact_path, signature=signature)\n",
        "\n",
        "    # Register the model to AML model registry\n",
        "    mlflow.register_model(\"runs:/\" + run.info.run_id + \"/\" + artifact_path, \"customer-churn-prediction-model\")"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
